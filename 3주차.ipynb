{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb68210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────  버전 ①  :  바로 실행되는 최소 코드  ────────────\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1) PDF를 불러올 로더와 자를 기준(청크 길이‧겹침)을 준비\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1_000, chunk_overlap=100)\n",
    "loader   = UnstructuredFileLoader(\"./files/일임형ISA실무지침.pdf\")\n",
    "\n",
    "# 2) PDF → langchain Document → 지정한 길이로 잘라서 docs 리스트에 담기\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "print(f\"문서 조각 개수: {len(docs)}\")      # 예: 123\n",
    "print(docs[0].page_content[:200])          # 첫 청크 미리보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 문서 600자 단위 청크 만들기  (버전 ① : 실행용 최소 코드)\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 1) 600글자씩, 100글자 겹치기로 자를 가위 준비\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "# 2) PDF 파일을 읽어올 로더 준비  ← 경로·파일명만 바뀌었어요!\n",
    "loader = PyPDFLoader(\"./files/일임형ISA실무지침.pdf\")\n",
    "\n",
    "# 3) 로드 + 분할\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "print(f\"청크 개수: {len(docs)}\")\n",
    "print(docs[0].page_content[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF → Chroma (OpenAI 임베딩 3-small 사용, 캐시 포함)\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters               import CharacterTextSplitter\n",
    "from langchain_openai                       import OpenAIEmbeddings\n",
    "from langchain.embeddings                   import CacheBackedEmbeddings\n",
    "from langchain_community.vectorstores       import Chroma\n",
    "from langchain.storage                      import LocalFileStore\n",
    "\n",
    "cache = LocalFileStore(\"./.cache\")\n",
    "\n",
    "# 1) 문서 로드·분할\n",
    "docs = PyPDFLoader(\"./files/일임형ISA실무지침.pdf\") \\\n",
    "         .load_and_split(CharacterTextSplitter(\n",
    "             separator=\"\\n\", chunk_size=600, chunk_overlap=100\n",
    "         ))\n",
    "\n",
    "# 2) ➡️ 3-small 임베딩으로 교체 (차원 512 권장)\n",
    "base_emb = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=512\n",
    ")\n",
    "emb = CacheBackedEmbeddings.from_bytes_store(base_emb, cache)\n",
    "\n",
    "# 3) Chroma 벡터 DB\n",
    "vectorstore = Chroma.from_documents(docs, emb)\n",
    "\n",
    "# 4) 테스트 질의\n",
    "for i, doc in enumerate(vectorstore.similarity_search(\n",
    "        \"일임형 ISA에서 납입 한도는 얼마인가요?\", k=3), 1):\n",
    "    print(f\"\\n--- 결과 {i} ---\\n{doc.page_content[:300]} …\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b732bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF → FAISS 벡터 DB + RetrievalQA  (버전 ① : 실행용 최소 코드)\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters               import CharacterTextSplitter\n",
    "from langchain_openai                       import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.embeddings                   import CacheBackedEmbeddings\n",
    "from langchain_community.vectorstores       import FAISS\n",
    "from langchain.storage                      import LocalFileStore\n",
    "from langchain.chains                       import RetrievalQA\n",
    "\n",
    "# ── 0. LLM & 캐시 ───────────────────────────\n",
    "llm   = ChatOpenAI()                   # GPT-4o 등 OpenAI 모델\n",
    "cache = LocalFileStore(\"./.cache\")     # 임베딩 캐시 폴더\n",
    "\n",
    "# ── 1. PDF 로드 + 분할 ──────────────────────\n",
    "loader   = PyPDFLoader(\"./files/일임형ISA실무지침.pdf\")\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=600, chunk_overlap=100)\n",
    "docs     = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "# ── 2. 임베딩 (캐시 래핑) ────────────────────\n",
    "base_emb   = OpenAIEmbeddings()\n",
    "cached_emb = CacheBackedEmbeddings.from_bytes_store(base_emb, cache)\n",
    "\n",
    "# ── 3. FAISS 벡터스토어 구축 ────────────────\n",
    "vectorstore = FAISS.from_documents(docs, cached_emb)\n",
    "\n",
    "# ── 4. RetrievalQA 체인 ▶ map_rerank 방식 ──\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_rerank\", #여기에 다양한 방식을 넣을수있음 stuff 나 map_reduce나\n",
    "    retriever=vectorstore.as_retriever(k=4),   # 상위 4개 문단 후보\n",
    ")\n",
    "\n",
    "answer = qa_chain.run(\"일임형 ISA의 연간 납입 한도는 얼마인가요?\")\n",
    "print(\"\\n[답변]\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc4829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF → FAISS 벡터 DB + 맞춤 프롬프트 QA            (하나하나씩 다설명)\n",
    "\n",
    "# (필요한 모듈 불러오기)\n",
    "from langchain_community.document_loaders import PyPDFLoader          # PDF 읽는 친구\n",
    "from langchain_text_splitters               import CharacterTextSplitter   # 글 자르는 가위\n",
    "from langchain_openai                       import ChatOpenAI, OpenAIEmbeddings # GPT 두뇌 & 숫자 변환 두뇌\n",
    "from langchain.embeddings                   import CacheBackedEmbeddings   # 두뇌 결과를 기억하는 상자\n",
    "from langchain_community.vectorstores       import FAISS               # 비슷한 글 찾기 도서관\n",
    "from langchain.storage                      import LocalFileStore       # 캐시 넣을 폴더\n",
    "from langchain_core.prompts                 import ChatPromptTemplate   # 챗봇 말버릇 만들기\n",
    "from langchain_core.runnables               import RunnablePassthrough  # 질문 그대로 pass!\n",
    "\n",
    "# (0) 캐시 폴더와 GPT 준비\n",
    "cache_folder = LocalFileStore(\"./.cache\")    # “.cache” 폴더에 기억 저장\n",
    "llm          = ChatOpenAI(temperature=0.1)   # 말 잘하는 GPT, 차분하게\n",
    "\n",
    "# (1) PDF 읽고 600글자씩(앞뒤 100글자 겹치며) 자르기\n",
    "loader   = PyPDFLoader(\"./files/일임형ISA실무지침.pdf\")      # PDF 파일 고르기\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",        # 줄바꿈을 기준으로\n",
    "    chunk_size=600,        # 한 조각 600글자\n",
    "    chunk_overlap=100      # 앞과 뒤가 100글자씩 겹쳐요\n",
    ")\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "# (2) 글 조각을 숫자(벡터)로 바꿔 주는 두뇌 + 캐시\n",
    "base_emb      = OpenAIEmbeddings()\n",
    "cached_emb    = CacheBackedEmbeddings.from_bytes_store(base_emb, cache_folder)\n",
    "\n",
    "# (3) 숫자 벡터를 FAISS 도서관에 보관\n",
    "vector_db = FAISS.from_documents(docs, cached_emb)\n",
    "\n",
    "# (4) “어울리는 글 4개만 찾아줘!” 하는 검색 도구(retriever) 만들기\n",
    "retriever = vector_db.as_retriever(k=4)\n",
    "\n",
    "# (5) 챗봇에게 “이런 말버릇으로 대답해!” 하고 알려주는 프롬프트\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a helpful assistant. Answer questions using only the following \"\n",
    "     \"context. If you don't know the answer, just say you don't know:\\n\\n{context}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# (6) 질문 → 검색 → 프롬프트 → GPT 순으로 이어붙인 체인\n",
    "qa_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# (7) 궁금한 것을 물어보기!\n",
    "question = \"일임형 ISA 계좌의 연간 납입 한도는 얼마인가요?\"\n",
    "print(\"[질문] \", question)\n",
    "print(\"[답변] \", qa_chain.invoke(question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF → FAISS + map-reduce QA          \n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader            # PDF 읽는 친구\n",
    "from langchain_text_splitters               import CharacterTextSplitter     # 글 자르는 가위\n",
    "from langchain_openai                       import ChatOpenAI, OpenAIEmbeddings # GPT 두뇌 & 숫자 변환 두뇌\n",
    "from langchain.embeddings                   import CacheBackedEmbeddings     # 두뇌 결과 기억 상자\n",
    "from langchain_community.vectorstores       import FAISS                 # 비슷한 글 찾기 도서관\n",
    "from langchain.storage                      import LocalFileStore         # 캐시 폴더\n",
    "from langchain_core.prompts                 import ChatPromptTemplate     # 챗봇 말버릇\n",
    "from langchain_core.runnables               import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# (0) GPT 와 캐시 준비\n",
    "llm   = ChatOpenAI(temperature=0.1)           # 차분하게 대답하는 GPT\n",
    "cache = LocalFileStore(\"./.cache\")            # \".cache\" 폴더에 기억 저장\n",
    "\n",
    "# (1) PDF 읽고 600글자씩(100글자 겹치며) 자르기\n",
    "loader   = PyPDFLoader(\"./files/일임형ISA실무지침.pdf\")\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", chunk_size=600, chunk_overlap=100\n",
    ")\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "# (2) 글 조각을 숫자(벡터)로 바꿀 두뇌 + 캐시\n",
    "base_emb   = OpenAIEmbeddings()\n",
    "cached_emb = CacheBackedEmbeddings.from_bytes_store(base_emb, cache)\n",
    "\n",
    "# (3) 숫자 벡터를 FAISS 도서관에 저장\n",
    "vector_db = FAISS.from_documents(docs, cached_emb)\n",
    "\n",
    "# (4) “비슷한 글 6개 찾아줘!” 검색 도구\n",
    "retriever = vector_db.as_retriever(k=6)\n",
    "\n",
    "# (5) 문단 하나하나가 ‘도움 되는지’ GPT로 점검 (map 단계)\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"아래 글이 질문에 도움이 되면 그대로 돌려주고, 아니면 ''만 돌려줘.\\n------\\n{context}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "def map_docs(inputs):\n",
    "    \"\"\"검색 결과 각 문단을 GPT에게 보여 주고, 도움이 되는 부분만 모아 돌려줘요.\"\"\"\n",
    "    docs_   = inputs[\"documents\"]\n",
    "    quest   = inputs[\"question\"]\n",
    "    pieces  = [\n",
    "        map_doc_chain.invoke({\"context\": d.page_content, \"question\": quest}).content\n",
    "        for d in docs_\n",
    "    ]\n",
    "    joined  = \"\\n\\n\".join(p for p in pieces if p.strip())\n",
    "    return joined or \"''\"\n",
    "\n",
    "map_chain = (\n",
    "    {\"documents\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | RunnableLambda(map_docs)\n",
    ")\n",
    "\n",
    "# (6) 모아온 ‘도움 되는 글’만 보고 최종 답변 (reduce 단계)\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"문맥에 있는 정보만 사용해 대답해. 모르면 모른다고 해.\\n------\\n{context}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": map_chain, \"question\": RunnablePassthrough()}\n",
    "    | final_prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# (7) 궁금한 걸 물어보기!\n",
    "question = \"일임형 ISA 관련 법령에서 언급된 ‘납입 한도’는 연간 얼마인가요?\"\n",
    "print(\"[질문]\", question)\n",
    "print(\"[답변]\", qa_chain.invoke(question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF → FAISS + map-reduce QA (신형 임베딩)\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters               import CharacterTextSplitter\n",
    "from langchain_openai                       import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.embeddings                   import CacheBackedEmbeddings\n",
    "from langchain_community.vectorstores       import FAISS\n",
    "from langchain.storage                      import LocalFileStore\n",
    "from langchain_core.prompts                 import ChatPromptTemplate\n",
    "from langchain_core.runnables               import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm   = ChatOpenAI(temperature=0.1)\n",
    "cache = LocalFileStore(\"./.cache\")\n",
    "\n",
    "# 1) 문서 로드 & 분할\n",
    "docs = (\n",
    "    PyPDFLoader(\"./files/일임형ISA실무지침.pdf\")\n",
    "    .load_and_split(\n",
    "        CharacterTextSplitter(separator=\"\\n\", chunk_size=600, chunk_overlap=100)\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2) 새 임베딩 모델 지정\n",
    "base_emb = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=512)\n",
    "emb      = CacheBackedEmbeddings.from_bytes_store(base_emb, cache)\n",
    "\n",
    "# 3) FAISS 벡터 DB\n",
    "db        = FAISS.from_documents(docs, emb)\n",
    "retriever = db.as_retriever(k=6)\n",
    "\n",
    "# 4) map 단계\n",
    "map_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"아래 글이 질문에 도움이 되면 그대로 돌려주고, 아니면 ''만 돌려줘.\\n------\\n{context}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "map_chain = map_prompt | llm\n",
    "\n",
    "def filter_docs(inp):\n",
    "    q = inp[\"question\"]\n",
    "    return \"\\n\\n\".join(\n",
    "        map_chain.invoke({\"context\": d.page_content, \"question\": q}).content\n",
    "        for d in inp[\"documents\"]\n",
    "    ) or \"''\"\n",
    "\n",
    "map_pipe = (\n",
    "    {\"documents\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | RunnableLambda(filter_docs)\n",
    ")\n",
    "\n",
    "# 5) reduce 단계\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"문맥 정보만 사용해서 답해. 모르면 모른다고 해.\\n------\\n{context}\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": map_pipe, \"question\": RunnablePassthrough()}\n",
    "    | final_prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "print(qa_chain.invoke(\"일임형 ISA 관련 법령에서 언급된 ‘납입 한도’는 연간 얼마인가요?\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
